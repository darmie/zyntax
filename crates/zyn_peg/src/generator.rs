//! Code generator for ZynPEG
//!
//! Generates Rust code from .zyn grammars:
//! 1. A pest parser (from the PEG patterns)
//! 2. A TypedAST builder (from the action blocks)

use proc_macro2::TokenStream;
use quote::{quote, format_ident};
use crate::{ZynGrammar, RuleDef, RuleModifier};
use crate::error::{Result, ZynPegError};

/// Generate complete Rust code from a ZynGrammar
pub fn generate_parser(grammar: &ZynGrammar) -> Result<GeneratedCode> {
    let pest_grammar = generate_pest_grammar(grammar)?;
    let ast_builder = generate_ast_builder(grammar)?;
    let parser_impl = generate_parser_impl(grammar)?;

    Ok(GeneratedCode {
        pest_grammar,
        ast_builder,
        parser_impl,
    })
}

/// Generated code components
pub struct GeneratedCode {
    /// The .pest grammar file content
    pub pest_grammar: String,
    /// The TypedAST builder Rust code
    pub ast_builder: TokenStream,
    /// The parser implementation with parse_to_typed_ast method
    pub parser_impl: TokenStream,
}

/// Generate a pest-compatible grammar from ZynGrammar rules
fn generate_pest_grammar(grammar: &ZynGrammar) -> Result<String> {
    let mut lines = Vec::new();

    // Add header comment
    lines.push(format!(
        "// Generated by ZynPEG from {}.zyn",
        grammar.language.name.to_lowercase()
    ));
    lines.push(String::new());

    // Generate each rule
    for rule in &grammar.rules {
        let modifier = match rule.modifier {
            Some(RuleModifier::Atomic) => "@",
            Some(RuleModifier::Silent) => "_",
            Some(RuleModifier::Compound) => "$",
            Some(RuleModifier::NonAtomic) => "!",
            None => "",
        };

        lines.push(format!(
            "{} = {}{{ {} }}",
            rule.name, modifier, rule.pattern
        ));
    }

    // Add standard whitespace/comment rules if not defined
    let has_whitespace = grammar.rules.iter().any(|r| r.name == "WHITESPACE");
    let has_comment = grammar.rules.iter().any(|r| r.name == "COMMENT");

    if !has_whitespace {
        lines.push(String::new());
        lines.push("WHITESPACE = _{ \" \" | \"\\t\" | \"\\n\" | \"\\r\" }".to_string());
    }

    if !has_comment {
        lines.push("COMMENT = _{ \"//\" ~ (!\"\\n\" ~ ANY)* ~ \"\\n\"? }".to_string());
    }

    Ok(lines.join("\n"))
}

/// Generate the TypedAST builder code
fn generate_ast_builder(grammar: &ZynGrammar) -> Result<TokenStream> {
    let imports = parse_imports(&grammar.imports.code);
    let context_fields = generate_context_fields(&grammar.context);
    let type_helpers = parse_type_helpers(&grammar.type_helpers.code);

    // Generate build methods for each rule with an action
    let build_methods: Vec<TokenStream> = grammar.rules.iter()
        .filter(|r| r.action.is_some())
        .map(|r| generate_build_method(r))
        .collect::<Result<Vec<_>>>()?;

    Ok(quote! {
        // Generated imports
        #imports

        /// TypedAST builder context
        pub struct AstBuilderContext<'a> {
            #context_fields
        }

        impl<'a> AstBuilderContext<'a> {
            #type_helpers

            #(#build_methods)*
        }
    })
}

/// Generate the parser implementation
fn generate_parser_impl(grammar: &ZynGrammar) -> Result<TokenStream> {
    let parser_name = format_ident!("{}Parser", to_pascal_case(&grammar.language.name));
    let grammar_file = format!("{}.pest", grammar.language.name.to_lowercase());

    Ok(quote! {
        use pest_derive::Parser;

        #[derive(Parser)]
        #[grammar = #grammar_file]
        pub struct #parser_name;

        impl #parser_name {
            /// Parse source code to TypedAST
            pub fn parse_to_typed_ast(
                input: &str,
                arena: &mut AstArena,
                type_registry: &mut TypeRegistry,
            ) -> Result<TypedProgram, ParseError> {
                use pest::Parser;

                // Parse with pest
                let pairs = Self::parse(Rule::program, input)?;

                // Build TypedAST
                let mut ctx = AstBuilderContext { arena, type_registry };
                ctx.build_program(pairs)
            }
        }
    })
}

/// Generate a build method for a rule with an action
fn generate_build_method(rule: &RuleDef) -> Result<TokenStream> {
    let action = rule.action.as_ref()
        .ok_or_else(|| ZynPegError::InvalidAction("No action for rule".into()))?;

    let method_name = format_ident!("build_{}", rule.name);
    let return_type: TokenStream = action.return_type.parse()
        .map_err(|e| ZynPegError::CodeGenError(format!("Invalid return type: {}", e)))?;

    // Check if this is a raw code action or structured fields
    let body = if let Some(ref raw_code) = action.raw_code {
        // Raw code action - embed the code directly
        let code = process_capture_refs(raw_code);
        let code_tokens: TokenStream = code.parse()
            .unwrap_or_else(|_| quote! { todo!("Failed to parse raw code") });
        quote! { #code_tokens }
    } else {
        // Structured field assignments
        let field_assignments: Vec<TokenStream> = action.fields.iter()
            .map(|f| {
                let name = format_ident!("{}", f.name);
                let value = process_capture_refs(&f.value);
                let value_tokens: TokenStream = value.parse()
                    .unwrap_or_else(|_| quote! { todo!("Failed to parse field value") });
                quote! { #name: #value_tokens }
            })
            .collect();

        quote! {
            #return_type {
                #(#field_assignments,)*
            }
        }
    };

    Ok(quote! {
        /// Build a #return_type from a parsed rule
        fn #method_name(&mut self, pair: pest::iterators::Pair<Rule>) -> Result<#return_type, ParseError> {
            let inner: Vec<_> = pair.clone().into_inner().collect();
            let span = pair.as_span();

            // Helper: get child by index (1-based in grammar, 0-based here)
            let get_child = |idx: usize| -> Option<&pest::iterators::Pair<Rule>> {
                inner.get(idx.saturating_sub(1))
            };

            // Helper: get child text
            let get_text = |idx: usize| -> &str {
                inner.get(idx.saturating_sub(1)).map(|p| p.as_str()).unwrap_or("")
            };

            Ok(#body)
        }
    })
}

/// Process capture references like $1, $2, $name
/// Transforms capture refs into proper Rust code for accessing parsed children
fn process_capture_refs(value: &str) -> String {
    let mut result = value.to_string();

    // Replace $N with get_child(N) or get_text(N) depending on context
    // For now, use a simpler approach: inner.get(N-1)
    for i in (1..=9).rev() {  // Reverse to handle $10+ before $1
        let pattern = format!("${}", i);
        // Use get_child for accessing child pairs, get_text for text content
        let replacement = format!("get_child({})", i);
        result = result.replace(&pattern, &replacement);
    }

    result
}

/// Parse imports string into TokenStream
fn parse_imports(code: &str) -> TokenStream {
    if code.is_empty() {
        return quote! {};
    }

    code.parse().unwrap_or_else(|_| quote! {
        // Failed to parse imports
    })
}

/// Generate context field declarations
fn generate_context_fields(context: &[crate::ContextVar]) -> TokenStream {
    let fields: Vec<TokenStream> = context.iter().map(|v| {
        let name = format_ident!("{}", v.name);
        let ty: TokenStream = v.ty.parse().unwrap_or_else(|_| quote! { () });
        quote! { pub #name: #ty }
    }).collect();

    quote! { #(#fields,)* }
}

/// Parse type helpers code
fn parse_type_helpers(code: &str) -> TokenStream {
    if code.is_empty() {
        return quote! {};
    }

    code.parse().unwrap_or_else(|_| quote! {
        // Failed to parse type helpers
    })
}

/// Convert string to PascalCase
fn to_pascal_case(s: &str) -> String {
    let mut result = String::new();
    let mut capitalize_next = true;

    for c in s.chars() {
        if c == '_' || c == '-' || c == ' ' {
            capitalize_next = true;
        } else if capitalize_next {
            result.push(c.to_ascii_uppercase());
            capitalize_next = false;
        } else {
            result.push(c.to_ascii_lowercase());
        }
    }

    result
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_to_pascal_case() {
        assert_eq!(to_pascal_case("hello"), "Hello");
        assert_eq!(to_pascal_case("hello_world"), "HelloWorld");
        assert_eq!(to_pascal_case("zig"), "Zig");
        assert_eq!(to_pascal_case("my_parser"), "MyParser");
    }

    #[test]
    fn test_process_capture_refs() {
        assert_eq!(process_capture_refs("$1"), "get_child(1)");
        assert_eq!(process_capture_refs("$1 + $2"), "get_child(1) + get_child(2)");
        assert_eq!(process_capture_refs("foo($1, $3)"), "foo(get_child(1), get_child(3))");
    }

    #[test]
    fn test_generate_pest_grammar() {
        let grammar = ZynGrammar {
            language: crate::LanguageInfo {
                name: "Test".to_string(),
                ..Default::default()
            },
            rules: vec![
                RuleDef {
                    name: "number".to_string(),
                    modifier: Some(RuleModifier::Atomic),
                    pattern: "ASCII_DIGIT+".to_string(),
                    action: None,
                },
                RuleDef {
                    name: "expr".to_string(),
                    modifier: None,
                    pattern: "number | \"(\" ~ expr ~ \")\"".to_string(),
                    action: None,
                },
            ],
            ..Default::default()
        };

        let pest = generate_pest_grammar(&grammar).unwrap();
        assert!(pest.contains("number = @{ ASCII_DIGIT+ }"));
        assert!(pest.contains("expr = { number | \"(\" ~ expr ~ \")\" }"));
        assert!(pest.contains("WHITESPACE"));
    }
}
